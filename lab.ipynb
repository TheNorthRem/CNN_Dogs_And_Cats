{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 预处理训练集，将训练集的猫与狗分为训练集和测试集，分别存放到对应的目录中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "\n",
    "data_set_dir = './data_set'\n",
    "\n",
    "train_dir = './train'\n",
    "\n",
    "validation_dir = './validation'\n",
    "\n",
    "test_dir = './test'\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir,'cat')\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir,'dog')\n",
    "\n",
    "cats_validation_dir = os.path.join(validation_dir,'cat')\n",
    "\n",
    "dogs_validation_dir = os.path.join(validation_dir,'dog')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(train_dir)\n",
    "\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "os.mkdir(train_cats_dir)\n",
    "\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "os.mkdir(cats_validation_dir)\n",
    "\n",
    "os.mkdir(dogs_validation_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练数据迁移  划分 前 10000个为训练集 后2500个为测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set_build(type,target_dir):\n",
    "\n",
    "    file_names = ['{}.{}.jpg'.format(type,i) for i in range (8000)]\n",
    "\n",
    "    for file_name in file_names :\n",
    "        src = os.path.join(data_set_dir,file_name)\n",
    "        dst = os.path.join(target_dir,file_name)\n",
    "        shutil.copyfile(src,dst)\n",
    "\n",
    "    file_names = ['{}.{}.jpg'.format(type,i) for i in range (8000,10000)]\n",
    "\n",
    "    for file_name in file_names :\n",
    "       src = os.path.join(data_set_dir,file_name)\n",
    "       dst = os.path.join(validation_dir,type)\n",
    "       dst = os.path.join(dst,file_name)\n",
    "       shutil.copyfile(src,dst)\n",
    "\n",
    "    file_names = ['{}.{}.jpg'.format(type,i) for i in range (10000,12500)]\n",
    "\n",
    "    for file_name in file_names :\n",
    "        src = os.path.join(data_set_dir,file_name)\n",
    "        dst = os.path.join(test_dir,file_name)\n",
    "        shutil.copyfile(src,dst)\n",
    "\n",
    "data_set_build('cat',train_cats_dir)\n",
    "data_set_build('dog',train_dogs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通卷积模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(223, 223, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于Resnet网络架构构建网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "def resnet_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备开始模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input_shape = (223, 223, 3)\n",
    "# num_classes = 2\n",
    "# model = resnet_model(input_shape, num_classes)\n",
    "\n",
    "model = resnet_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = ImageDataGenerator(rescale=1./255)\n",
    "test_image = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_image.flow_from_directory(train_dir,\n",
    "                                             target_size=(224,224),\n",
    "                                             batch_size=20,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "validation_generator = test_image.flow_from_directory(validation_dir,\n",
    "                                                 target_size=(224,224),\n",
    "                                                 batch_size=20,\n",
    "                                                  class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, batch_size=32, epochs=10, validation_data=validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
